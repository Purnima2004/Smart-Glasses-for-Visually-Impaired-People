{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: googlemaps in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy matplotlib googlemaps requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head <b>north</b> - 10 ft\n",
      "Turn <b>right</b> - 62 ft\n",
      "Turn <b>left</b> - 230 ft\n",
      "Turn <b>left</b> - 0.1 mi\n",
      "Turn <b>right</b> - 174 ft\n",
      "Turn <b>right</b> - 59 ft\n",
      "Sharp <b>right</b><div style=\"font-size:0.9em\">Take the stairs</div> - 62 ft\n",
      "Turn <b>left</b> - 0.2 mi\n",
      "Turn <b>right</b> toward <b>Charleston Rd</b> - 33 ft\n",
      "Turn <b>left</b> onto <b>Charleston Rd</b> - 92 ft\n",
      "Turn <b>right</b> onto <b>N Shoreline Blvd</b> - 1.2 mi\n",
      "Slight <b>left</b> to stay on <b>N Shoreline Blvd</b> - 315 ft\n",
      "Slight <b>left</b> onto <b>Stierlin Rd</b> - 0.5 mi\n",
      "Turn <b>right</b> onto <b>Moffett Blvd</b> - 82 ft\n",
      "Turn <b>left</b> onto <b>Central Expy</b> - 39 ft\n",
      "Turn <b>right</b> onto <b>Castro St</b> - 59 ft\n",
      "Turn <b>left</b> - 449 ft\n",
      "Take the crosswalk - 144 ft\n",
      "Turn <b>left</b> toward <b>W Evelyn Ave</b> - 39 ft\n",
      "Turn <b>right</b> toward <b>W Evelyn Ave</b> - 220 ft\n",
      "Turn <b>right</b> toward <b>W Evelyn Ave</b> - 82 ft\n",
      "Turn <b>left</b> onto <b>W Evelyn Ave</b> - 2.5 mi\n",
      "Turn <b>right</b> onto <b>S Mathilda Ave</b><div style=\"font-size:0.9em\">Pass by PNC Bank (on the right in 0.2 mi)</div> - 1.2 mi\n",
      "Continue straight onto <b>Sunnyvale Saratoga Rd</b> - 0.7 mi\n",
      "Slight <b>left</b> toward <b>Sunnyvale Saratoga Rd</b> - 236 ft\n",
      "Slight <b>right</b> onto <b>Sunnyvale Saratoga Rd</b> - 1.1 mi\n",
      "Continue onto <b>N De Anza Blvd</b> - 0.3 mi\n",
      "Take the exit on the <b>left</b> - 69 ft\n",
      "Turn <b>right</b> - 0.2 mi\n"
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Google Maps Client\n",
    "API_KEY = 'AIzaSyCWR8imz2EUl_m7N8cnoNfsBKhRzHH4d68'\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "# Get directions from start to end point\n",
    "start = \"37.4221,-122.0841\"  # Latitude, Longitude format\n",
    "end = \"37.3318,-122.0312\"\n",
    "\n",
    "\n",
    "directions_result = gmaps.directions(start,end,mode=\"walking\",departure_time=datetime.now())\n",
    "\n",
    "# Print step-by-step directions\n",
    "for step in directions_result[0]['legs'][0]['steps']:\n",
    "    print(step['html_instructions'], \"-\", step['distance']['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (8.3.27)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (5.9.7)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\purnima ji sahoo\\Documents\\Navigation_model_epics\\Screenshot 2024-11-28 170723.png: 640x480 1 person, 171.0ms\n",
      "Speed: 9.0ms preprocess, 171.0ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Class: 0.0, Confidence: 0.9210246801376343, Box: [223.71998596191406, 333.3880310058594, 394.57354736328125, 798.3329467773438]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Replace 'yolov8.pt' with the path to your model file\n",
    "\n",
    "# Load an image for detection\n",
    "image_path = 'Screenshot 2024-11-28 170723.png'  # Replace with the path to your input image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform object detection\n",
    "results = model.predict(source=image_path, show=True)  # show=True displays the image with bounding boxes\n",
    "\n",
    "# Process results\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Bounding boxes\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]  # Extract box coordinates\n",
    "        conf = box.conf[0]  # Confidence score\n",
    "        cls = box.cls[0]  # Class label\n",
    "\n",
    "        print(f\"Class: {cls}, Confidence: {conf}, Box: [{x1}, {y1}, {x2}, {y2}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 107.0ms\n",
      "Speed: 2.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 banana, 140.0ms\n",
      "Speed: 8.0ms preprocess, 140.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 113.0ms\n",
      "Speed: 9.0ms preprocess, 113.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 108.0ms\n",
      "Speed: 9.9ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 107.0ms\n",
      "Speed: 7.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 160.0ms\n",
      "Speed: 11.0ms preprocess, 160.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.0ms\n",
      "Speed: 7.0ms preprocess, 141.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 118.0ms\n",
      "Speed: 3.0ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.0ms\n",
      "Speed: 2.0ms preprocess, 92.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 89.0ms\n",
      "Speed: 7.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 106.0ms\n",
      "Speed: 5.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 196.0ms\n",
      "Speed: 12.0ms preprocess, 196.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.0ms\n",
      "Speed: 2.0ms preprocess, 115.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 105.0ms\n",
      "Speed: 4.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.0ms\n",
      "Speed: 6.0ms preprocess, 95.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 106.0ms\n",
      "Speed: 5.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.0ms\n",
      "Speed: 5.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.0ms\n",
      "Speed: 9.0ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 117.0ms\n",
      "Speed: 9.0ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.1ms\n",
      "Speed: 8.1ms preprocess, 113.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.0ms\n",
      "Speed: 7.0ms preprocess, 111.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 106.0ms\n",
      "Speed: 7.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 110.0ms\n",
      "Speed: 6.0ms preprocess, 110.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 110.5ms\n",
      "Speed: 10.0ms preprocess, 110.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.0ms\n",
      "Speed: 5.0ms preprocess, 111.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.0ms\n",
      "Speed: 4.0ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 102.0ms\n",
      "Speed: 5.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.0ms\n",
      "Speed: 1.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 102.5ms\n",
      "Speed: 5.0ms preprocess, 102.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 104.0ms\n",
      "Speed: 9.0ms preprocess, 104.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.0ms\n",
      "Speed: 8.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 91.0ms\n",
      "Speed: 6.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 108.0ms\n",
      "Speed: 5.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 109.0ms\n",
      "Speed: 7.9ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 102.0ms\n",
      "Speed: 7.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.0ms\n",
      "Speed: 6.0ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 101.0ms\n",
      "Speed: 7.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 100.0ms\n",
      "Speed: 6.9ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 118.0ms\n",
      "Speed: 5.9ms preprocess, 118.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 118.0ms\n",
      "Speed: 9.0ms preprocess, 118.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 108.0ms\n",
      "Speed: 10.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 100.0ms\n",
      "Speed: 6.0ms preprocess, 100.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.0ms\n",
      "Speed: 8.0ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 107.0ms\n",
      "Speed: 7.9ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 101.0ms\n",
      "Speed: 5.0ms preprocess, 101.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.0ms\n",
      "Speed: 3.0ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 106.0ms\n",
      "Speed: 5.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 101.0ms\n",
      "Speed: 8.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.0ms\n",
      "Speed: 2.0ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 100.5ms\n",
      "Speed: 7.0ms preprocess, 100.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 120.0ms\n",
      "Speed: 4.3ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 103.0ms\n",
      "Speed: 7.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 102.0ms\n",
      "Speed: 9.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 107.0ms\n",
      "Speed: 2.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 98.0ms\n",
      "Speed: 2.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.0ms\n",
      "Speed: 2.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 94.0ms\n",
      "Speed: 2.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 101.0ms\n",
      "Speed: 2.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 101.5ms\n",
      "Speed: 5.9ms preprocess, 101.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 104.6ms\n",
      "Speed: 6.0ms preprocess, 104.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 105.0ms\n",
      "Speed: 6.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 189.0ms\n",
      "Speed: 11.0ms preprocess, 189.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 109.6ms\n",
      "Speed: 6.0ms preprocess, 109.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.0ms\n",
      "Speed: 5.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.0ms\n",
      "Speed: 6.9ms preprocess, 115.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 105.0ms\n",
      "Speed: 6.9ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 103.0ms\n",
      "Speed: 6.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 107.0ms\n",
      "Speed: 6.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 91.0ms\n",
      "Speed: 2.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 109.0ms\n",
      "Speed: 6.0ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.0ms\n",
      "Speed: 2.0ms preprocess, 96.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Load video or live camera feed\n",
    "video_path = 0  # Use '0' for webcam or replace with a video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection on the frame\n",
    "    results = model.predict(source=frame, show=True)\n",
    "\n",
    "    # Display results\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Convert to integers\n",
    "            conf = box.conf[0]\n",
    "            cls = box.cls[0]\n",
    "\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'{cls} {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('YOLOv8 Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.8)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from pyttsx3) (306)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_instruction(instruction):\n",
    "    print(f\"Instruction: {instruction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: osmnx in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: geopandas<0.15,>=0.12 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from osmnx) (0.14.4)\n",
      "Requirement already satisfied: networkx<3.4,>=2.5 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from osmnx) (3.3)\n",
      "Requirement already satisfied: numpy<1.27,>=1.20 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from osmnx) (1.26.4)\n",
      "Requirement already satisfied: pandas<2.3,>=1.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from osmnx) (2.2.2)\n",
      "Requirement already satisfied: requests<2.33,>=2.27 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from osmnx) (2.32.3)\n",
      "Requirement already satisfied: shapely<2.1,>=2.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from osmnx) (2.0.6)\n",
      "Requirement already satisfied: fiona>=1.8.21 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from geopandas<0.15,>=0.12->osmnx) (1.10.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from geopandas<0.15,>=0.12->osmnx) (23.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from geopandas<0.15,>=0.12->osmnx) (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from pandas<2.3,>=1.1->osmnx) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from pandas<2.3,>=1.1->osmnx) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from pandas<2.3,>=1.1->osmnx) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests<2.33,>=2.27->osmnx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests<2.33,>=2.27->osmnx) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests<2.33,>=2.27->osmnx) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from requests<2.33,>=2.27->osmnx) (2024.8.30)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas<0.15,>=0.12->osmnx) (23.1.0)\n",
      "Requirement already satisfied: click~=8.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas<0.15,>=0.12->osmnx) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas<0.15,>=0.12->osmnx) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas<0.15,>=0.12->osmnx) (0.7.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=1.1->osmnx) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\purnima ji sahoo\\appdata\\roaming\\python\\python312\\site-packages (from click~=8.0->fiona>=1.8.21->geopandas<0.15,>=0.12->osmnx) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize components\n",
    "API_KEY = 'AIzaSyCWR8imz2EUl_m7N8cnoNfsBKhRzHH4d68'\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "model = YOLO('yolov8n.pt')  # Load YOLOv8 model\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Fetch Route\n",
    "def fetch_route(start, end):\n",
    "    directions = gmaps.directions(start, end, mode=\"walking\", departure_time=datetime.now())\n",
    "    steps = [(step['html_instructions'], step['distance']['text']) for step in directions[0]['legs'][0]['steps']]\n",
    "    return steps\n",
    "\n",
    "# Perform Object Detection\n",
    "def detect_objects(frame):\n",
    "    results = model.predict(source=frame, show=False)\n",
    "    detected_objects = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls = int(box.cls[0])  # Object class\n",
    "            conf = float(box.conf[0])  # Confidence score\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box\n",
    "            detected_objects.append({'class': cls, 'confidence': conf, 'box': (x1, y1, x2, y2)})\n",
    "    return detected_objects\n",
    "\n",
    "# Provide Audio Guidance\n",
    "def speak_instruction(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Main Pipeline\n",
    "def navigation_pipeline(start, end, video_source=0):\n",
    "    # Step 1: Fetch route\n",
    "    steps = fetch_route(start, end)\n",
    "    step_index = 0  # Track current step\n",
    "\n",
    "    # Step 2: Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Step 3: Detect objects\n",
    "        detected_objects = detect_objects(frame)\n",
    "\n",
    "        # Display object detection results on video feed\n",
    "        for obj in detected_objects:\n",
    "            x1, y1, x2, y2 = obj['box']\n",
    "            cls = obj['class']\n",
    "            conf = obj['confidence']\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Class: {cls}, Conf: {conf:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Step 4: Update navigation step based on position (this can use GPS or proximity logic)\n",
    "        if step_index < len(steps):\n",
    "            instruction, distance = steps[step_index]\n",
    "            speak_instruction(f\"Next step: {instruction}, {distance}\")\n",
    "            step_index += 1  # Move to the next step for this demo\n",
    "\n",
    "        # Show the video with detected objects\n",
    "        cv2.imshow(\"Navigation Feed\", frame)\n",
    "\n",
    "        # Break loop on 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\purnima ji sahoo\\anaconda3\\lib\\site-packages (from geopy) (2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Location: (21.116522, 79.548831)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "run loop already started",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m distance_to_destination \u001b[38;5;241m=\u001b[39m haversine(current_location[\u001b[38;5;241m0\u001b[39m], current_location[\u001b[38;5;241m1\u001b[39m], B[\u001b[38;5;241m0\u001b[39m], B[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distance_to_destination \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold_distance:\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mspeak_instruction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are close to your destination. Please proceed carefully.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_location \u001b[38;5;241m==\u001b[39m B \u001b[38;5;129;01mor\u001b[39;00m distance_to_destination \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:  \n\u001b[0;32m     71\u001b[0m         speak_instruction(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have reached your destination.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[55], line 28\u001b[0m, in \u001b[0;36mspeak_instruction\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspeak_instruction\u001b[39m(text):\n\u001b[0;32m     27\u001b[0m     engine\u001b[38;5;241m.\u001b[39msay(text)\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunAndWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyttsx3\\engine.py:180\u001b[0m, in \u001b[0;36mEngine.runAndWait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mRuns an event loop until all commands queued up until this method call\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03mcomplete. Blocks during the event loop and returns when the queue is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m@raise RuntimeError: When the loop is already running\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inLoop:\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun loop already started\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inLoop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driverLoop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: run loop already started"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pyttsx3\n",
    "import time\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "velocity = 1.4 \n",
    "fps = 1  \n",
    "threshold_distance = 1.5 \n",
    "\n",
    "\n",
    "A = (21.116512, 79.548809)  \n",
    "B = (21.116522, 79.548831)  \n",
    "\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  \n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(delta_phi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "\n",
    "def speak_instruction(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "def get_current_location():\n",
    "    global current_position, lat_increment, lon_increment, steps_remaining\n",
    "\n",
    "    if steps_remaining <= 0:\n",
    "        return B  \n",
    "\n",
    "    # Update position\n",
    "    current_position = (\n",
    "        current_position[0] + lat_increment,\n",
    "        current_position[1] + lon_increment\n",
    "    )\n",
    "    steps_remaining -= 1\n",
    "    return current_position\n",
    "\n",
    "\n",
    "def initialize_navigation(start, end, velocity, fps):\n",
    "    global current_position, lat_increment, lon_increment, steps_remaining\n",
    "\n",
    "    current_position = start \n",
    "    total_distance = haversine(start[0], start[1], end[0], end[1])\n",
    "    steps_remaining = int(total_distance / (velocity / fps))\n",
    "\n",
    "    # Calculate latitude and longitude increments per step\n",
    "    lat_increment = (end[0] - start[0]) / steps_remaining\n",
    "    lon_increment = (end[1] - start[1]) / steps_remaining\n",
    "\n",
    "\n",
    "initialize_navigation(A, B, velocity, fps)\n",
    "\n",
    "\n",
    "for i in range(steps_remaining + 1):\n",
    "    current_location = get_current_location()\n",
    "    print(f\"Current Location: {current_location}\")\n",
    "    \n",
    "\n",
    "    distance_to_destination = haversine(current_location[0], current_location[1], B[0], B[1])\n",
    "    \n",
    "    if distance_to_destination <= threshold_distance:\n",
    "        speak_instruction(\"You are close to your destination. Please proceed carefully.\")\n",
    "        if current_location == B or distance_to_destination < 1:  \n",
    "            speak_instruction(\"You have reached your destination.\")\n",
    "            print(\"Destination reached!\")\n",
    "            break\n",
    "    \n",
    "    \n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_proximity(current_location, destination_location, threshold=5):\n",
    "    # Calculate distance to the next step\n",
    "    distance = geopy.distance.geodesic(current_location, destination_location).meters\n",
    "    return distance <= threshold  # Returns True if within threshold meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_route_for_obstacle(obstacle_location, current_route, gmaps):\n",
    "    # Call Google Maps API for rerouting\n",
    "    new_route = gmaps.directions(\n",
    "        origin=obstacle_location,\n",
    "        destination=current_route['end'],\n",
    "        mode=\"walking\",\n",
    "        departure_time=datetime.now()\n",
    "    )\n",
    "    return new_route\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_proximity_alert(current_location, obstacle_location, threshold=5):\n",
    "    distance = geopy.distance.geodesic(current_location, obstacle_location).meters\n",
    "    if distance <= threshold:\n",
    "        return \"Warning: Obstacle ahead!\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_navigation_steps(current_location, steps):\n",
    "    for i, step in enumerate(steps):\n",
    "        step_location = step['end_location']  # Assume each step has an 'end_location'\n",
    "        if check_proximity(current_location, step_location):\n",
    "            return steps[i + 1:]  # Return remaining steps after current\n",
    "    return steps  # No steps updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_off_route(current_location, expected_route, threshold=10):\n",
    "    for waypoint in expected_route:\n",
    "        if check_proximity(current_location, waypoint, threshold):\n",
    "            return False  \n",
    "    return True  \n",
    "\n",
    "def reroute_user(current_location, destination, gmaps):\n",
    "    new_route = gmaps.directions(\n",
    "        origin=current_location,\n",
    "        destination=destination,\n",
    "        mode=\"walking\",\n",
    "        departure_time=datetime.now()\n",
    "    )\n",
    "    return new_route\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_real_time_audio_feedback(instruction):\n",
    "    engine.say(instruction)\n",
    "    engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_direction_arrow(frame, start_point, end_point):\n",
    "    cv2.arrowedLine(frame, start_point, end_point, (255, 0, 0), 5, cv2.LINE_AA)\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigation_pipeline_real_time(start, end, video_source=0):\n",
    "    steps = fetch_route(start, end)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        current_location = get_current_location()  # Step 1: Track user location\n",
    "        detected_objects = detect_objects(frame)  # Step 2: Detect obstacles\n",
    "\n",
    "        # Step 3: Proximity-based updates\n",
    "        if steps and check_proximity(current_location, steps[0]['end_location']):\n",
    "            speak_instruction(f\"Next step: {steps[0]['html_instructions']}\")\n",
    "            steps.pop(0)  # Move to the next step\n",
    "\n",
    "        # Step 4: Check for rerouting\n",
    "        if check_off_route(current_location, steps):\n",
    "            steps = reroute_user(current_location, end, gmaps)\n",
    "\n",
    "        # Step 5: Visual and audio feedback\n",
    "        for obj in detected_objects:\n",
    "            provide_real_time_audio_feedback(provide_proximity_alert(current_location, obj['box']))\n",
    "        cv2.imshow(\"Navigation Feed\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
